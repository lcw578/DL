# 基于深度学习的三色图像分类系统
## 一、代码流程和细节
### 1.1 数据预处理
在这次训练数据集样本的过程中，我进行了图像转换，统一了图片的输入尺寸，转换成张量，再进行正则化。这个预处理步骤是必要的，因为深度学习模型需要统一的输入格式。统一输入尺寸确保了所有图片都是64×64像素，避免了尺寸不一致导致的计算问题。将图片转换为张量是因为PyTorch只能处理张量格式的数据。正则化将像素值从0-255映射到-1到1的范围，这样可以加速模型收敛，避免梯度消失或爆炸的问题。

### 1.2 数据加载机制
通过加载训练集样本，我让模型在我的GPU上面进行训练。我选择的训练批次为1024，这个批次大小是经过权衡的结果。批次太小会导致梯度更新不稳定且训练时间长，批次太大会超出GPU内存限制。1024的批次大小既能充分利用GPU的并行计算能力，又能保证训练的稳定性。我使用了DataLoader来管理数据加载，其中shuffle=True表示每个epoch都会打乱数据顺序，这样可以防止模型记住数据的顺序，提高泛化能力。pin_memory=True表示将数据加载到固定内存中以加速GPU训练，这样可以减少CPU到GPU的数据传输时间。

### 1.3 训练核心流程
在训练过程中，数据会先通过我搭建的神经网络进行前向传播，接着通过损失函数计算出反向传播时的损失总和，利用ADAM优化器来更新参数，以尽可能减小损失。清零梯度是必要的，因为PyTorch会累积梯度，如果不清零会导致梯度越来越大。前向传播计算模型的预测结果，损失计算衡量预测与真实标签的差距。反向传播计算每个参数的梯度，优化器根据梯度更新参数。这个循环过程让模型逐渐学会正确分类。

### 1.4 验证策略
每经过十次训练轮数进行评估，打印一次训练情况。这个频率既能及时监控训练效果，又不会过于频繁影响训练效率。我同时在test1和test2两个测试集上验证模型性能，这样做的原因是防止模型过拟合到单一测试集。使用两个独立的测试集可以更好地评估模型的泛化能力。我计算了平均准确率和最低准确率两个指标，平均准确率反映整体性能，最低准确率确保模型在两个测试集上都有良好表现，避免了只在一个测试集上表现好的情况。

## 二、网络模型设计
### 2.1 整体架构
我搭建的神经网络为三个卷积块加上三个全连接层。选择这种架构的原因是它能够有效提取图像特征并进行分类。卷积层负责特征提取，全连接层负责分类决策。三个卷积块的设计遵循了CNN的经典模式，能够从低级特征逐步抽象到高级特征。

### 2.2 卷积块设计
每个卷积块中都包含了一个卷积层，一个归一化层，一个最大池化层，并且以RELU作为我的激活函数。

卷积层负责特征提取，通过卷积核扫描图像来检测不同的视觉模式。我选择3×3的卷积核是因为它既能捕获局部特征，又能保持较少的参数量。padding=1确保输出尺寸与输入尺寸相同，避免特征图过快缩小。

批归一化层的作用是标准化每一层的输入，这样可以加速训练收敛，提高训练稳定性，还能起到一定的正则化效果。RELU激活函数引入非线性，让网络能够学习复杂的特征映射，同时计算简单，不会出现梯度消失问题。

最大池化层的作用是降低特征图尺寸，减少参数量和计算量，同时增强特征的平移不变性。每次池化都将尺寸减半，从64×64最终缩小到8×8。

通道数设计为3→32→64→128，这种递增设计是有道理的。浅层需要较少通道检测基本特征如边缘，深层需要更多通道来表示复杂的语义特征。

### 2.3 全连接层设计
在全连接层上，我采用了三个全连接层，也都是以RELU作为激活函数。前两个全连接层包含了全连接和dropout，最后一个全连接层没有dropout。

第一个全连接层将8192维的特征向量压缩到512维，这是一个特征降维的过程，去除冗余信息，保留重要特征。dropout设置为0.5是因为这一层参数最多，最容易过拟合，需要较强的正则化。

第二个全连接层进一步压缩到128维，dropout降低到0.3，因为参数量减少，过拟合风险降低。最后的输出层直接输出3个类别的logits，不使用dropout是为了保持预测的稳定性。

暂退法在前向传播过程中，计算每一内部层的同时丢弃一些神经元。暂退法可以避免过拟合，它通常与控制权重向量的维数和大小结合使用的。

### 2.4 Softmax回归和损失函数
我在最后添加了Softmax回归，将logits转换为概率分布。这样做的好处是输出结果更容易解释，每个类别的概率值在0-1之间，所有概率之和为1。

我采用交叉熵损失函数作为我的损失函数，它特别适合多分类任务，能够有效地度量预测概率分布与真实标签之间的差异。

ADAM作为我的优化器，它自适应学习率，收敛相比于SGD可能会更快。ADAM结合了动量法和自适应学习率的优点，能够自动调整每个参数的学习率，在稀疏梯度情况下表现更好。

## 三、创新点
### 3.1 参考并简化了ALEXNET的网络模型
这是本项目的主要创新点。原始的AlexNet结构复杂，参数量庞大，不适合小规模数据集。我的简化版本保留了AlexNet的核心思想，即通过多层卷积和池化逐步提取特征，但大幅减少了层数和参数量。

结构简化的好处是训练更快，内存占用更少，不容易过拟合。我用BatchNorm替代了原始的局部响应归一化，这是更现代的做法，效果更好。总参数量约17.42MB，相比原始AlexNet大幅减少，适合中小规模数据集。

### 3.2 可以将图片信息通过多通道输出
这体现在渐进式的通道扩展设计：从RGB的3通道开始，逐步扩展到32、64、128通道。这种设计的原理是，浅层特征简单，需要的通道数少；深层特征复杂，需要更多通道来表示。

每个通道可以看作是一个特征检测器，32个通道可以检测32种不同的低级特征，128个通道可以表示128种高级特征。这种多通道并行处理提高了特征提取的丰富性和准确性。